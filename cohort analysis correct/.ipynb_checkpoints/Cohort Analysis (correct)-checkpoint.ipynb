{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names_to_months(x):\n",
    "    a = re.sub(\"\\D\", \"\", x)[:4]\n",
    "    if len(a) > 0:\n",
    "        a = a[:4]\n",
    "    elif x == \"*\":\n",
    "        a = 'install'\n",
    "    else:\n",
    "        a = x\n",
    "    return a\n",
    "\n",
    "def set_na_values(df):\n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(df.shape[1]-1):\n",
    "            if (current_date - datetime.strptime(df.index[i], \"%Y-%m-%d\")).days < int(df.columns[j]):\n",
    "                df.iat[i,j] = np.nan\n",
    "    return df\n",
    "\n",
    "def inverse_cumsum(df_cumsum): \n",
    "    df = df_cumsum.iloc[:,4:].copy()\n",
    "    a = df.as_matrix()\n",
    "    df = pd.DataFrame(np.append(a[:,:1], a[:,1:] - a[:,:-1], axis=1), columns = df.columns, index = df.index)\n",
    "    return df\n",
    "\n",
    "def monthly_aggregation_normed(df, grouping_col_name):\n",
    "    col_names = df.columns\n",
    "    col_names = list(col_names[col_names != grouping_col_name])\n",
    "    daily_metric = df.copy()\n",
    "    daily_metric.index = daily_metric.index.map(lambda x: datetime.strptime(x, \"%Y-%m-%d\").strftime('%Y-%m'))\n",
    "    daily_metrics = pd.DataFrame(index = sorted(set(daily_metric.index)))\n",
    "    for col_name in col_names:\n",
    "        daily_metric_one = daily_metric[[grouping_col_name, col_name]].dropna()\n",
    "        daily_metric_one = daily_metric_one.groupby(daily_metric_one.index).sum()\n",
    "        daily_metrics = pd.concat([daily_metrics, daily_metric_one[col_name] / daily_metric_one[grouping_col_name]], join='outer', axis = 1)\n",
    "    daily_metrics.columns = col_names\n",
    "    return daily_metrics\n",
    "\n",
    "def monthly_aggregation(df, grouping_col_name):\n",
    "    col_names = df.columns\n",
    "    col_names = list(col_names[col_names != grouping_col_name])\n",
    "    daily_metric = df.copy()\n",
    "    daily_metric.index = daily_metric.index.map(lambda x: datetime.strptime(x, \"%Y-%m-%d\").strftime('%Y-%m'))\n",
    "    daily_metrics = pd.DataFrame(index = sorted(set(daily_metric.index)))\n",
    "    for col_name in col_names:\n",
    "        daily_metric_one = daily_metric[[grouping_col_name, col_name]].dropna()\n",
    "        daily_metric_one = daily_metric_one.groupby(daily_metric_one.index).sum()\n",
    "        daily_metrics = pd.concat([daily_metrics, daily_metric_one[col_name]], join='outer', axis = 1)\n",
    "    daily_metrics.columns = col_names\n",
    "    return daily_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def culc_payments_all_days_cumsum_reg(df_payments, df_reg):\n",
    "    \"\"\" Cumulative sum of payments by all days from install and by all days from install \"\"\"\n",
    "    m_payments_all_days = df_payments.pivot_table(index='registration day', columns='days from registration', values='revenue in cents', aggfunc=sum).fillna(0).applymap(float)\n",
    "    m_payments_all_days = pd.concat([m_payments_all_days, m_reg.drop(m_reg.columns, axis = 1)], join='outer', axis = 1).fillna(0)\n",
    "    m_payments_all_days_cumsum = np.cumsum(m_payments_all_days, axis = 1)\n",
    "    m_payments_all_days_cumsum = set_na_values(m_payments_all_days_cumsum)\n",
    "    m_payments_all_days_cumsum = m_payments_all_days_cumsum[list(map(lambda x: max(m_payments_all_days_cumsum.columns[m_payments_all_days_cumsum.columns < x]), interesting_days))]\n",
    "    m_payments_all_days_cumsum.columns = list(map(str, interesting_days))\n",
    "    m_payments_all_days_cumsum_reg = pd.concat([m_payments_all_days_cumsum, m_reg[['install']]], join='outer', axis = 1)\n",
    "    return m_payments_all_days_cumsum_reg\n",
    "\n",
    "def culc_payers_cumsum_reg(df_payments, m_retention_reg, interesting_days):\n",
    "    \"\"\" Payers in this and previous months \"\"\"\n",
    "    m_payers_cumsum = m_retention_reg.drop(m_retention_reg.columns, axis = 1)\n",
    "    for day in interesting_days:\n",
    "        m_payers_cumsum = pd.concat([m_payers_cumsum, df_payments[df_payments['days from registration'] <= day].groupby('registration day')['user ID'].agg(lambda x: len(set(x)))], join='outer', axis = 1).fillna(0)\n",
    "    m_payers_cumsum.columns = list(map(str, interesting_days))\n",
    "    m_payers_cumsum_reg = pd.concat([m_payers_cumsum, m_retention_reg['install']], join='outer', axis = 1)\n",
    "    return m_payers_cumsum_reg\n",
    "\n",
    "def culc_payers_reg(df_payments, m_retention_reg, interesting_days):\n",
    "    \"\"\" Payers in this month \"\"\"\n",
    "    m_payers = m_retention_reg.drop(m_retention_reg.columns, axis = 1)\n",
    "    days = [-1] + interesting_days\n",
    "    for i in range(1, len(days)):\n",
    "        m_payers = pd.concat([m_payers, df_payments[(df_payments['days from registration'] > days[i-1]) & (df_payments['days from registration'] <= days[i])].groupby('registration day')['user ID'].agg(lambda x: len(set(x)))], join='outer', axis = 1).fillna(0)\n",
    "    m_payers.columns = list(map(str, interesting_days))\n",
    "    m_payers_reg = pd.concat([m_payers, m_retention_reg[['install']]], join='outer', axis = 1)\n",
    "    return m_payers_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.strptime('2018-04-22', \"%Y-%m-%d\")\n",
    "border_install_date = '2018-04-01'\n",
    "interesting_days = [1, 3, 7, 14] + list(range(30, 30*38, 30))\n",
    "apps = ['android','ios','st','vk','ok','fb']\n",
    "refs = ['notref','ref']\n",
    "variable_list = ['retention_reg','reg_monthly','retention_monthly','payments_cumsum_monthly','payments_monthly',\n",
    "                 'payers_cumsum_monthly','payers_monthly','retention_monthly_norm_reg','payers_cumsum_monthly_norm_reg',\n",
    "                 'payers_monthly_norm_reg','payers_monthly_norm_mau','payments_monthly_norm_mau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rewrite payments\n",
    "#for ref in refs:\n",
    "#    for app in apps:\n",
    "#        print(app, ref)\n",
    "#        df1 = pd.read_csv(\"_\".join(['./data/180316',app,ref,'payments.csv']))\n",
    "#        df2 = pd.read_csv(\"_\".join(['./data/180425',app,ref,'payments.csv']))\n",
    "#        df1 = df1[df1['payment date'] < '2018-03-16']\n",
    "#        df2 = df2[df2['payment date'] >= '2018-03-16']\n",
    "#        df = pd.concat([df1, df2])\n",
    "#        df.to_csv(\"_\".join(['./data/_180425',app,ref,'payments.csv']), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load retention days and installs\n",
    "# https://portraits.core.tf/app/kibana?#/visualize/create?type=histogram&indexPattern=portraits&_g=(refreshInterval:(display:Off,pause:!f,value:0),time:(from:now-15m,mode:quick,to:now))&_a=(filters:!(),linked:!f,query:(query_string:(analyze_wildcard:!t,query:'created:%5B%222015-01-01T00:00:00%22%20TO%202018-02-28T23:59:59%5D%20AND%20referral:0')),uiState:(),vis:(aggs:!((id:'1',params:(),schema:metric,type:count),(id:'2',params:(customInterval:'2h',extended_bounds:(),field:created,interval:d,min_doc_count:1),schema:segment,type:date_histogram),(id:'3',params:(filters:!(('$$hashKey':'object:655',input:(query:(query_string:(analyze_wildcard:!t,query:'first_app:topfacemobappandroid'))),label:''),('$$hashKey':'object:665',input:(query:(query_string:(analyze_wildcard:!t,query:'first_app:topfacemobappios')))),('$$hashKey':'object:670',input:(query:(query_string:(analyze_wildcard:!t,query:'first_app:standalonetf')))),('$$hashKey':'object:675',input:(query:(query_string:(analyze_wildcard:!t,query:'first_app:topface%20AND%20platform:vk')))),('$$hashKey':'object:680',input:(query:(query_string:(analyze_wildcard:!t,query:'first_app:topface%20AND%20platform:ok')))),('$$hashKey':'object:685',input:(query:(query_string:(analyze_wildcard:!t,query:'first_app:topface%20AND%20platform:fb')))))),schema:group,type:filters),(id:'4',params:(filters:!(('$$hashKey':'object:738',input:(query:(query_string:(analyze_wildcard:!t,query:'*'))),label:''),('$$hashKey':'object:747',input:(query:(query_string:(analyze_wildcard:!t,query:'retention_days:1')))),('$$hashKey':'object:751',input:(query:(query_string:(analyze_wildcard:!t,query:'retention_days:3')))),('$$hashKey':'object:755',input:(query:(query_string:(analyze_wildcard:!t,query:'retention_days:7')))),('$$hashKey':'object:759',input:(query:(query_string:(analyze_wildcard:!t,query:'retention_days:14')))),('$$hashKey':'object:768',input:(query:(query_string:(analyze_wildcard:!t,query:'retention_days:30')))),('$$hashKey':'object:772',input:(query:(query_string:(analyze_wildcard:!t,query:'retention_days:60')))),('$$hashKey':'object:777',input:(query:(query_string:(analyze_wildcard:!t,query:'retention_days:90')))),('$$hashKey':'object:782',input:(query:(query_string:(analyze_wildcard:!t,query:'retention_days:120')))),('$$hashKey':'object:788',input:(query:(query_string:(analyze_wildcard:!t,query:'retention_days:150')))),('$$hashKey':'object:793',input:(query:(query_string:(analyze_wildcard:!t,query:'retention_days:180'))))),row:!t),schema:split,type:filters)),listeners:(),params:(addLegend:!t,addTimeMarker:!f,addTooltip:!t,defaultYExtents:!f,mode:stacked,scale:linear,setYExtents:!f,shareYAxis:!t,times:!(),yAxis:()),title:'New%20Visualization',type:histogram))\n",
    "df_retention_days_all_notref = pd.read_csv(r'./data/notref_retention_days.csv',thousands=',')\n",
    "df_retention_days_all_ref = pd.read_csv(r'./data/ref_retention_days.csv',thousands=',')\n",
    "df_retention_days_all_notref['ref'] = 'notref'\n",
    "df_retention_days_all_ref['ref'] = 'ref'\n",
    "df_retention_days_all = df_retention_days_all_notref.append(df_retention_days_all_ref)\n",
    "df_retention_days_all.columns = ['created per day', 'app', 'retention day', 'users', 'ref']\n",
    "dict_app = {'first_app:topfacemobappandroid': 'android','first_app:topfacemobappios':'ios','first_app:standalonetf':'st',\n",
    "            'first_app:topface AND platform:vk' : 'vk', 'first_app:topface AND platform:ok': 'ok','first_app:topface AND platform:fb': 'fb'}\n",
    "df_retention_days_all['app'] = df_retention_days_all['app'].map(dict_app)\n",
    "df_retention_days_all['retention day'] = df_retention_days_all['retention day'].map(lambda x: names_to_months(x))\n",
    "df_retention_days_all = df_retention_days_all[df_retention_days_all['created per day'] < border_install_date]\n",
    "df_retention_days_all['created per day'] = df_retention_days_all['created per day'].map(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").strftime('%Y-%m-%d'))\n",
    "df_retention_days_all['days from current date'] = (current_date - df_retention_days_all['created per day'].map(lambda x: datetime.strptime(x, \"%Y-%m-%d\"))).map(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android notref\n",
      "ios notref\n",
      "st notref\n",
      "vk notref\n",
      "ok notref\n",
      "fb notref\n",
      "android ref\n",
      "ios ref\n",
      "st ref\n",
      "vk ref\n",
      "ok ref\n",
      "fb ref\n"
     ]
    }
   ],
   "source": [
    "### Load payments\n",
    "for ref in refs:\n",
    "    for app in apps:\n",
    "        print(app, ref)\n",
    "        df = pd.read_csv(\"_\".join(['./data/180425',app,ref,'payments.csv']))\n",
    "        df['app'] = app\n",
    "        df['ref'] = ref\n",
    "        df = df[df['registration date'] < border_install_date]\n",
    "        df['payment date'] = df['payment date'].map(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "        df['registration date'] = df['registration date'].map(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))  \n",
    "        df['payment day'] = df['payment date'].map(lambda x: x.strftime('%Y-%m-%d'))\n",
    "        df['registration day'] = df['registration date'].map(lambda x: x.strftime('%Y-%m-%d'))\n",
    "        df['registration month'] = df['registration date'].map(lambda x: x.strftime('%Y-%m'))\n",
    "        df['time from registration'] = df['payment date'] - df['registration date']\n",
    "        df['days from registration'] = df['time from registration'].map(lambda x: x.days)\n",
    "        if 'df_payments_all' in vars():\n",
    "            df_payments_all = df_payments_all.append(df)\n",
    "        else:\n",
    "            df_payments_all = df\n",
    "df_payments_all = df_payments_all[df_payments_all['registration date'] >= '2015-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android notref\n",
      "ios notref\n",
      "st notref\n",
      "vk notref\n",
      "ok notref\n",
      "fb notref\n",
      "android ref\n",
      "ios ref\n",
      "st ref\n",
      "vk ref\n",
      "ok ref\n",
      "fb ref\n"
     ]
    }
   ],
   "source": [
    "for ref in refs:\n",
    "    for app in apps:\n",
    "        print(app, ref)\n",
    "        df_retention_days = df_retention_days_all[(df_retention_days_all['app'] == app) & (df_retention_days_all['ref'] == ref)]\n",
    "        \n",
    "        m_retention_reg = df_retention_days.pivot_table(index='created per day', columns='retention day', values='users', aggfunc=sum).fillna(0).applymap(float)\n",
    "        m_retention_reg = m_retention_reg[['1','3','7','14','30','60','90','120','150','180','install']]\n",
    "        m_retention_reg = set_na_values(m_retention_reg)\n",
    "        m_reg = m_retention_reg[['install']]\n",
    "        m_reg_monthly = m_retention_reg[['install']].groupby(m_retention_reg.index.map(lambda x: datetime.strptime(x, \"%Y-%m-%d\").strftime('%Y-%m'))).sum()\n",
    "        m_retention_monthly_norm_reg = monthly_aggregation_normed(m_retention_reg, 'install')\n",
    "        m_retention_monthly = monthly_aggregation(m_retention_reg, 'install')\n",
    "        \n",
    "\n",
    "        df_payments = df_payments_all[(df_payments_all['app'] == app) & (df_payments_all['ref'] == ref)]\n",
    "        \n",
    "        m_payments_all_days_cumsum_reg = culc_payments_all_days_cumsum_reg(df_payments, m_reg)\n",
    "        m_payments_cumsum_monthly_norm_reg = monthly_aggregation_normed(m_payments_all_days_cumsum_reg, 'install')\n",
    "        m_payments_monthly_norm_reg = inverse_cumsum(m_payments_cumsum_monthly_norm_reg)\n",
    "        m_payments_cumsum_monthly = monthly_aggregation(m_payments_all_days_cumsum_reg, 'install')\n",
    "        m_payments_monthly = inverse_cumsum(m_payments_cumsum_monthly)\n",
    "        \n",
    "        m_payers_cumsum_reg = culc_payers_cumsum_reg(df_payments, m_retention_reg, interesting_days)\n",
    "        m_payers_cumsum_monthly_norm_reg = monthly_aggregation_normed(m_payers_cumsum_reg, 'install')\n",
    "        m_payers_cumsum_monthly = monthly_aggregation(m_payers_cumsum_reg, 'install')\n",
    "        \n",
    "        m_payers_reg = culc_payers_reg(df_payments, m_reg, interesting_days[4:])\n",
    "        m_payers_monthly_norm_reg = monthly_aggregation_normed(m_payers_reg, 'install')\n",
    "        m_payers_monthly = monthly_aggregation(m_payers_reg, 'install')\n",
    "        \n",
    "        m_retention_monthly_6_months = pd.concat([m_reg_monthly, m_retention_monthly[['60','90','120','150','180']]], join='outer', axis = 1)\n",
    "        m_retention_monthly_6_months.columns = ['30','60','90','120','150','180']\n",
    "        m_payers_monthly_norm_mau = m_payers_monthly[['30','60','90','120','150','180']] / m_retention_monthly_6_months[['30','60','90','120','150','180']]\n",
    "        m_payments_monthly_norm_mau = m_payments_monthly[['30','60','90','120','150','180']] / m_retention_monthly_6_months[['30','60','90','120','150','180']]\n",
    "        \n",
    "        m_retention_reg = m_retention_reg[['install','1','3','7','14','30','60','90','120','150','180']]\n",
    "        \n",
    "        writer = pd.ExcelWriter('./out/cohort_analysis_correct' + '_' + ref + '_' + app + '.xlsx')\n",
    "        for variable in variable_list:\n",
    "            if bool(re.search('retention.*norm',variable)):\n",
    "                round(vars()['m_' + variable] * 100, 2).to_excel(writer,variable)\n",
    "            elif bool(re.search('norm',variable)):\n",
    "                round(vars()['m_' + variable], 4).to_excel(writer,variable)\n",
    "            else:\n",
    "                vars()['m_' + variable].to_excel(writer,variable)\n",
    "        writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
